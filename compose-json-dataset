#!/usr/bin/python

import json
import argparse
import os
import sys
import re
import base64

def scale_coords(coords, width=900, height=600):
    coords = [(float(x), float(y)) for x, y in coords]
    minx = min(x for x, y in coords)
    miny = min(y for x, y in coords)
    maxx = max(x for x, y in coords)
    maxy = max(y for x, y in coords)

    scale_x = width / (maxx - minx)
    scale_y = height / (maxy - miny)
    print scale_x, scale_y, minx, miny, maxx, maxy
    scaled = []
    for x, y in coords:
        scaled.append([(x - minx) * scale_x, (y - miny) * scale_y])

    return scaled


def merge_data(name):
    """merge x, y, thumbnail data url, big image url
    """
    f = open('names/%s.txt' % name)
    thumbnail_names = [x.strip() for x in f]
    f.close()
    f = open('maps-2d/%s.csv' % name)
    coords = scale_coords([x.split(',') for x in f])
    f.close()
    data = []
    for thumbnail, coords in zip(thumbnail_names, coords):
        #XXX won't work for non-jpgs
        img_link = re.sub(r'^(?:big-)?thumbnails/(\d+)\.png$', r'images/\1.jpg',
                          thumbnail)
        x, y = coords
        data.append([x, y, thumbnail, img_link])

    return data


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('-i', '--dataset-id',
                        help='dataset id to use')
    args= parser.parse_args()

    d = merge_data(args.dataset_id)
    f = open(os.path.join('datasets', '%s.json' % args.dataset_id), 'w')
    json.dump(d, f)
    f.close()

main()
